

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>End-to-End Model-Free Reinforcement Learning for Urban Driving using Implicit Affordances &mdash; DI-drive 0.3.4 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
    
    <script type="text/javascript" src="../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Latent Reinforcement Learning" href="latent_rl.html" />
    <link rel="prev" title="BeV Speed End-to-end Reinforcement Learning" href="simple_rl.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../index.html" class="icon icon-home"> DI-drive
          

          
          </a>

          
            
            
              <div class="version">
                0.3.4
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../installation/index.html">Installation</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../tutorial/index.html">Tutorial</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../features/index.html">Features</a></li>
</ul>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Model Zoo</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="index.html#imitation-learning-model-zoo">Imitation Learning Model Zoo</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="index.html#reinforcement-learning-model-zoo">Reinforcement Learning Model Zoo</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="simple_rl.html">BeV Speed End-to-end Reinforcement Learning</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">End-to-End Model-Free Reinforcement Learning for Urban Driving using Implicit Affordances</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#training-models">Training Models</a></li>
<li class="toctree-l4"><a class="reference internal" href="#benchmarking-models">Benchmarking models</a></li>
<li class="toctree-l4"><a class="reference internal" href="#evaluation">Evaluation</a></li>
<li class="toctree-l4"><a class="reference internal" href="#training-cost">Training Cost</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="latent_rl.html">Latent Reinforcement Learning</a></li>
<li class="toctree-l3"><a class="reference internal" href="md_macro.html">MetaDrive Macro Environment</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="index.html#other-method">Other Method</a></li>
</ul>
</li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../api_doc/index.html">API Doc</a></li>
</ul>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../faq/index.html">FAQ</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">DI-drive</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../index.html">Docs</a> &raquo;</li>
        
          <li><a href="index.html">Model Zoo</a> &raquo;</li>
        
      <li>End-to-End Model-Free Reinforcement Learning for Urban Driving using Implicit Affordances</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../_sources/model_zoo/implicit.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="end-to-end-model-free-reinforcement-learning-for-urban-driving-using-implicit-affordances">
<h1>End-to-End Model-Free Reinforcement Learning for Urban Driving using Implicit Affordances<a class="headerlink" href="#end-to-end-model-free-reinforcement-learning-for-urban-driving-using-implicit-affordances" title="Permalink to this heading">¶</a></h1>
<div class="toctree-wrapper compound">
</div>
<p><a class="reference external" href="https://arxiv.org/abs/1911.10868">Implicit Affordances</a> is an end-to-end auto driving
policy trained with Supervised Learning as well as Reinforcement Learning. It first trains
backbone network with some implicit information as label, then freezes the backbone network
and train the head of network using RL.
It takes 4-frame RGB captured by front camera as in put. The model of the two training stage
is shown as follow.</p>
<figure class="align-center" id="id1">
<a class="reference internal image-reference" href="../_images/implicit2.png"><img alt="implicit2" src="../_images/implicit2.png" style="width: 600px;" /></a>
<figcaption>
<p><span class="caption-text">SL training pipeline</span><a class="headerlink" href="#id1" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<figure class="align-center" id="id2">
<img alt="implicit1" src="../_images/implicit1.png" />
<figcaption>
<p><span class="caption-text">RL training pipeline</span><a class="headerlink" href="#id2" title="Permalink to this image">¶</a></p>
</figcaption>
</figure>
<p>We extend and modified some of the training and environment details to make <em>Implicit
Affordances</em> able to run in multi-lane maps in Carla. This is so far the <strong>first</strong> driving
policy to run <cite>FullTown</cite> navigation in Carla using Reinforcement Learning. It achieves the
same performance as in single-lane maps.</p>
<section id="training-models">
<h2>Training Models<a class="headerlink" href="#training-models" title="Permalink to this heading">¶</a></h2>
<ol class="arabic">
<li><p>Start one or more CARLA server instances</p></li>
<li><p>Prepare dataset for supervised leanring</p>
<blockquote>
<div><div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python collect_data.py
</pre></div>
</div>
<p>Something you need to modify in the config of <code class="docutils literal notranslate"><span class="pre">collect_data.py</span></code>:</p>
<ul class="simple">
<li><p>save_dir: the root dir of dataset</p></li>
<li><p>server: your Carla servers’ ip and port</p></li>
<li><p>env_num: how many subprocesses(envs) to use for collecting data</p></li>
</ul>
</div></blockquote>
</li>
<li><p>Pre-train the encoder in a supervised way</p>
<blockquote>
<div><div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python train_sl.py
</pre></div>
</div>
<p>Something you need to modify in <code class="docutils literal notranslate"><span class="pre">train_sl.py</span></code>:</p>
<ul class="simple">
<li><p>gpus: the list of gpus</p></li>
<li><p>log_dir: save log and models</p></li>
<li><p>dataset_dir: the root dir of dataset</p></li>
</ul>
</div></blockquote>
</li>
<li><p>Train the agent with reinforcement Learning, the log and models will be saved in <code class="docutils literal notranslate"><span class="pre">./log</span></code></p>
<blockquote>
<div><div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python train_rl.py --supervised_model_path /path/to/supervised_model.pth <span class="se">\</span>
--crop-sky
</pre></div>
</div>
<p>Something you need to modify in <code class="docutils literal notranslate"><span class="pre">train_rl.py</span></code>:</p>
<ul class="simple">
<li><p>train_host_ports: your Carla servers’ ip and port for training</p></li>
<li><p>val_host_ports: your Carla servers’ ip and port for evaluation</p></li>
<li><p>env_num: how many subprocesses(envs) to use for training</p></li>
<li><p>town: if you want to train agents in the environment with multiple lanes, it can be set to Town04. Otherwise, it can be set to Town01 or Town02</p></li>
</ul>
</div></blockquote>
</li>
</ol>
</section>
<section id="benchmarking-models">
<h2>Benchmarking models<a class="headerlink" href="#benchmarking-models" title="Permalink to this heading">¶</a></h2>
<ol class="arabic simple">
<li><p>Make dirs</p></li>
</ol>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir <span class="o">[</span>MODEL_PATH<span class="o">]</span> <span class="o">&amp;&amp;</span> <span class="nb">cd</span> <span class="o">[</span>MODEL_PATH<span class="o">]</span>
mkdir model_supervised
mkdir model_RL
</pre></div>
</div>
<ol class="arabic" start="2">
<li><p>Copy the pre-train model into <code class="docutils literal notranslate"><span class="pre">[MODEL_PATH]/model_supervised</span></code> and copy the rl model into <code class="docutils literal notranslate"><span class="pre">[MODEL_PATH]/model_RL</span></code></p></li>
<li><p>Run</p>
<blockquote>
<div><div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>python eval.py --crop-sky --path-folder-model <span class="o">[</span>MODEL_PATH<span class="o">]</span>
</pre></div>
</div>
<p>Something you need to modify in <code class="docutils literal notranslate"><span class="pre">eval.py</span></code>:</p>
<ul class="simple">
<li><p>server: your Carla servers’ ip and port</p></li>
<li><p>suit: set the maps and routes for testing (ex. town2, StraightTown01, ChangeLaneTown04)</p></li>
<li><p>env_num: how many subprocesses(envs) to use for evaluting</p></li>
</ul>
</div></blockquote>
</li>
</ol>
</section>
<section id="evaluation">
<h2>Evaluation<a class="headerlink" href="#evaluation" title="Permalink to this heading">¶</a></h2>
<section id="running-carla-server">
<h3>Running CARLA Server<a class="headerlink" href="#running-carla-server" title="Permalink to this heading">¶</a></h3>
<section id="with-display">
<h4>With Display<a class="headerlink" href="#with-display" title="Permalink to this heading">¶</a></h4>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>./CarlaUE4.sh --world-port<span class="o">=</span><span class="m">2000</span> -opengl <span class="c1"># If you run multiple servers at one time, you should modify the world port</span>
</pre></div>
</div>
</section>
<section id="without-display">
<h4>Without Display<a class="headerlink" href="#without-display" title="Permalink to this heading">¶</a></h4>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nv">SDL_VIDEODRIVER</span><span class="o">=</span>offscreen <span class="nv">SDL_HINT_CUDA_DEVICE</span><span class="o">=</span><span class="m">0</span> ./CarlaUE4.sh --world-port<span class="o">=</span><span class="m">2000</span> -opengl
 <span class="c1"># If you run multiple servers at one time, you should modify the world port</span>
</pre></div>
</div>
</section>
</section>
<section id="evaluation-for-town01">
<h3>Evaluation for Town01<a class="headerlink" href="#evaluation-for-town01" title="Permalink to this heading">¶</a></h3>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> demo/implicit
wget http://opendilab.org/download/DI-drive/implicit/models_town01.tar.gz
tar xvf models_town01.tar.gz
python eval.py --crop-sky --path-folder-model models_town01
</pre></div>
</div>
</section>
<section id="evaluation-for-town04">
<h3>Evaluation for Town04<a class="headerlink" href="#evaluation-for-town04" title="Permalink to this heading">¶</a></h3>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span><span class="nb">cd</span> demo/implicit
wget http://opendilab.org/download/DI-drive/implicit/models_town04.tar.gz
tar xvf models_town04.tar.gz
python eval.py --crop-sky --path-folder-model models_town04 <span class="c1">#</span>
</pre></div>
</div>
<p>Something you need to modify in <code class="docutils literal notranslate"><span class="pre">eval.py</span></code>:</p>
<ul class="simple">
<li><p>server: your Carla servers’ ip and port</p></li>
<li><p>suit: set the maps and routes for testing (ex. town2, StraightTown01,
ChangeLaneTown04)</p></li>
<li><p>env_num: how many subprocesses(envs) to use for evaluting</p></li>
</ul>
</section>
<section id="results">
<h3>Results<a class="headerlink" href="#results" title="Permalink to this heading">¶</a></h3>
<p>You can go to <a class="reference external" href="https://opendilab.github.io/DI-drive/features/carla_benchmark.html">Benckmark page</a>
to see results of the two provided pre-train weights.</p>
</section>
</section>
<section id="training-cost">
<h2>Training Cost<a class="headerlink" href="#training-cost" title="Permalink to this heading">¶</a></h2>
<ol class="arabic simple">
<li><p>Collect data: about 48Carla / hours</p></li>
<li><p>Pre-train the encoder: about 4 gpu (32G V100) / days</p></li>
<li><p>Train the agent(Single Lane): about 60Carla (32G V100) / days</p></li>
<li><p>Train the agent(Multiple Lanes): about 100Carla (32G V100) / days</p></li>
</ol>
</section>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="latent_rl.html" class="btn btn-neutral float-right" title="Latent Reinforcement Learning" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="simple_rl.html" class="btn btn-neutral float-left" title="BeV Speed End-to-end Reinforcement Learning" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2021, OpenDILab

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>